{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCASE 2016 DNN Baseline\n",
    "In this notebook, we implement the **Detection and Classification of Acoustic Scenes and Events challenge** 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppress warnings**: We need to supress warnings as we are going to use some sunctionality of an older version of *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras_aud library\n",
    "Clone [keras_aud](https://github.com/channelCS/keras_aud) and place the **path** in *ka_path* variable so that we can import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ka_path=\"your/path/here\"\n",
    "sys.path.insert(0, ka_path)\n",
    "from keras_aud import aud_audio, aud_feature\n",
    "from keras_aud import aud_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make imports**: We now import libraries which shall be required in this task. We use\n",
    "1. `csv` for reading `.csv` files.\n",
    "2. `cPickle` for reading `.f` pickle files.\n",
    "3. `scipy` for calculating `mode`\n",
    "4. `time` for calciulating *time to load* pickle files.\n",
    "5. `KFold` for kfold cross validation.\n",
    "6. `to_categorical` for reshaping *labels* into `num_classes`.\n",
    "7. `load_model` for loading a saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define paths**: We now tell the paths for **audio**, **features** and **texts**.\n",
    "\n",
    "| Variable        | Description                     |\n",
    "| :-------------  |:-------------                   |\n",
    "| `wav_dev_fd`    | Development audio folder        |\n",
    "| `wav_eva_fd`    | Evaluation audio folder         |\n",
    "| `dev_fd`        | Development features folder     |\n",
    "| `eva_fd`        | Evaluation features folder      |\n",
    "| `label_csv`     | Development meta file           |\n",
    "| `txt_eva_path`  | Evaluation test file            |\n",
    "| `new_p`         | Evaluation evaluate file        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_dev_fd   = 'audio/dev'\n",
    "wav_eva_fd   = 'audio/eva'\n",
    "dev_fd       = 'features/Fe/logmel'\n",
    "eva_fd       = 'features/Fe_eva/logmel'\n",
    "label_csv    = 'texts/development/meta.txt'\n",
    "txt_eva_path = 'texts/evaluation/test.txt'\n",
    "new_p        = 'texts/evaluation/evaluate.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Labels**: We give the names of all the labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [ 'bus', 'cafe/restaurant', 'car', 'city_center', 'forest_path', 'grocery_store', 'home', 'beach', \n",
    "            'library', 'metro_station', 'office', 'residential_area', 'train', 'tram', 'park' ]\n",
    "lb_to_id = { lb:id for id, lb in enumerate(labels) }\n",
    "id_to_lb = { id:lb for id, lb in enumerate(labels) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "This is where feature extraction takes place. We pass the\n",
    "1. Feature name such as mel, logmel, mfcc.\n",
    "2. Folder containing audios\n",
    "3. Folder where features will be extracted\n",
    "4. A yaml file containing parameters for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction complete!\n",
      "Feature found\n",
      "extraction complete!\n",
      "Feature found\n"
     ]
    }
   ],
   "source": [
    "aud_audio.extract('logmel', wav_dev_fd, dev_fd,'example.yaml')\n",
    "aud_audio.extract('logmel', wav_eva_fd, eva_fd,'example.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "We define all model parameters here.\n",
    "\n",
    "| Variable           | Description              | type       | Accepted values             |\n",
    "| :-------------     | :-------------           | :--------- | :---------                  |\n",
    "| `prep`             | mode to use              | `str`      | dev, eval                   |\n",
    "| `save_model`       | Whether to save model    | `bool`     |                             |\n",
    "| `model_type`       | Type of model            | `str`      | Dynamic, Functional, Static |\n",
    "| `model`            | Name of model            | `str`      | DNN, CNN, CRNN, RNN, FCRNN  |\n",
    "| `modelx`           | Name of model for saving | `str`      | Should end with `.h5`       |\n",
    "| `feature`          | Name of feature          | `str`      | mel, logmel, cqt, mfcc, zcr |\n",
    "|<td colspan=2 style=\"text-align:center\">**Works only for Functional**</td>|||\n",
    "| `dropout1`         | 1st Dropout              | `float`    |                             |\n",
    "| `act1`             | 1st Activation           | `str`      |                             |\n",
    "| `act2`             | 2nd Activation           | `str`      |                             |\n",
    "| `act3`             | 3rd Activation           | `str`      |                             |\n",
    "| `act4`             | 4th Activation           | `str`      | Only in case of DNN         |\n",
    "|<td colspan=2 style=\"text-align:center\">**Works for all Models**</td>|||\n",
    "| `input_neurons`    | Number of Neurons        | `int`      |                             |\n",
    "| `epochs`           | Number of Epochs         | `int`      |                             |\n",
    "| `batchsize`        | Batch Size               | `int`      |                             |\n",
    "| `num_classes`      | Number of classes        | `int`      |                             |\n",
    "| `filter_length`    | Size of Filter           | `int`      |                             |\n",
    "| `nb_filter`        | Number of Filters        | `int`      |                             |\n",
    "|<td colspan=2 style=\"text-align:center\">**Feature Parameters**</td>|||\n",
    "| `agg_num`          | Number of frames         | `int`      |                             |\n",
    "| `hop`              | Hop Length               | `int`      |                             |\n",
    "| `custom_check_ftr` | check for dimensions     | `bool`     | True: know dimension        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep='eval'               # Which mode to use(String) Can be dev or eval.\n",
    "save_model=False          # True when you want to save the model with weights.\n",
    "#Parameters that are passed to the model.\n",
    "model_type='Functional'   # Type of model Can be Dynamic or Functional or Static\n",
    "model='CNN'               # Name of model(String) Can be DNN or CNN\n",
    "feature=\"logmel\"          # Name of feature(String) Can be mel logmel cqt mfcc zcr \n",
    "#Works only for Functional\n",
    "dropout1=0.1             # 1st Dropout(Float) \n",
    "act1='relu'              # 1st Activation(String) \n",
    "act2='relu'              # 2nd Activation(String) \n",
    "act3='softmax'           # 3rd Activation(String) \n",
    "#Works for all Models\n",
    "input_neurons=400      # Number of Neurons(Integer) \n",
    "epochs=10              # Number of Epochs(Integer)\n",
    "batchsize=128          # Batch Size(Integer)\n",
    "num_classes=15         # Number of classes(Integer)\n",
    "filter_length=3        # Size of Filter(Integer)\n",
    "nb_filter=100          # Number of Filters(Integer)\n",
    "#Feature Parameters: that are passed to the features.\n",
    "agg_num=10             # Agg Number(Integer) Number of frames\n",
    "hop=10                 # Hop Length(Integer)\n",
    "custom_check_ftr=False # True when you know the feature dimension else False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paul=aud_model.Feature(feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAllData(fe_fd, csv_file, agg_num, hop):\n",
    "    \"\"\"\n",
    "    Input: Features folder(String), CSV file(String), agg_num(Integer), hop(Integer).\n",
    "    Output: Loaded features(Numpy Array) and labels(Numpy Array).\n",
    "    Loads all the features saved as pickle files.\n",
    "    \"\"\"\n",
    "    # read csv\n",
    "    with open( csv_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lis = list(reader)\n",
    "    \n",
    "    # init list\n",
    "    X3d_all = []\n",
    "    y_all = []\n",
    "    i=0\n",
    "    for li in lis:\n",
    "        # load data\n",
    "        [na, lb] = li[0].split('\\t')\n",
    "        na = na.split('/')[1][0:-4]\n",
    "        path = fe_fd + '/' + na + '.f'\n",
    "        try:\n",
    "            X = cPickle.load( open( path, 'rb' ) )\n",
    "        except Exception as e:\n",
    "            print 'Error while parsing',path\n",
    "            continue\n",
    "        # reshape data to (n_block, n_time, n_freq)\n",
    "        i+=1\n",
    "        X3d = aud_model.mat_2d_to_3d( X, agg_num, hop )\n",
    "        X3d_all.append( X3d )\n",
    "        y_all += [ lb_to_id[lb] ] * len( X3d )\n",
    "    \n",
    "    print \"Features loaded\",i                \n",
    "    print 'All files loaded successfully'\n",
    "    # concatenate list to array\n",
    "    X3d_all = np.concatenate( X3d_all )\n",
    "    y_all = np.array( y_all )\n",
    "    \n",
    "    return X3d_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(md,csv_file,new_p,model):\n",
    "    # load name of wavs to be classified\n",
    "    with open( csv_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lis = list(reader)\n",
    "    \n",
    "    # do classification for each file\n",
    "    names = []\n",
    "    pred_lbs = []\n",
    "    \n",
    "    for li in lis:\n",
    "        names.append( li[0] )\n",
    "        na = li[0][6:-4]\n",
    "        #audio evaluation name\n",
    "        fe_path = eva_fd + '/' + na + '.f'\n",
    "        X0 = cPickle.load( open( fe_path, 'rb' ) )\n",
    "        X0 = aud_model.mat_2d_to_3d( X0, agg_num, hop )\n",
    "        \n",
    "        X0 = aud_model.mat_3d_to_nd(model,X0)\n",
    "    \n",
    "        # predict\n",
    "        p_y_preds = md.predict(X0)        # probability, size: (n_block,label)\n",
    "        preds = np.argmax( p_y_preds, axis=-1 )     # size: (n_block)\n",
    "        b = scipy.stats.mode(preds)\n",
    "        pred = int( b[0] )\n",
    "        pred_lbs.append( id_to_lb[ pred ] )\n",
    "    \n",
    "    pred = []    \n",
    "    # write out result\n",
    "    for i1 in xrange( len( names ) ):\n",
    "        fname = names[i1] + '\\t' + pred_lbs[i1] + '\\n' \n",
    "        pred.append(fname)\n",
    "        \n",
    "    print 'write out finished!'\n",
    "    truth = open(new_p,'r').readlines()\n",
    "    pred = [i.split('\\t')[1].split('\\n')[0]for i in pred]\n",
    "    truth = [i.split('\\t')[1]for i in truth]\n",
    "    pred.sort()\n",
    "    truth.sort()\n",
    "    return truth,pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded 1170\n",
      "All files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "tr_X, tr_y = GetAllData( dev_fd, label_csv, agg_num, hop )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930L, 10L, 40L)\n",
      "(150930L,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_X.shape)\n",
    "print(tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if custom_check_ftr:\n",
    "    reqd_dim = 40\n",
    "    paul.check_dimension(reqd_dim,tr_X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930L, 1L, 10L, 40L)\n"
     ]
    }
   ],
   "source": [
    "tr_X=aud_model.mat_3d_to_nd(model,tr_X)\n",
    "print(tr_X.shape)\n",
    "dimx=tr_X.shape[-2]\n",
    "dimy=tr_X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if prep=='dev':\n",
    "    cross_validation=True\n",
    "else:\n",
    "    cross_validation=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if model_type=='Static':\n",
    "    miz=aud_model.Static_Model(input_neurons=input_neurons,cross_validation=cross_validation,\n",
    "        nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy)\n",
    "\n",
    "elif model_type=='Functional':\n",
    "    miz=aud_model.Functional_Model(input_neurons=input_neurons,cross_validation=cross_validation,dropout1=dropout1,\n",
    "        act1=act1,act2=act2,act3=act3,nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy)\n",
    "\n",
    "elif model_type=='Dynamic':\n",
    "    layers=4\n",
    "    acts=['relu','relu','relu','relu','relu']\n",
    "    drops=[0.1,0.1,0.1,0.1]\n",
    "    pools=[2,2,2]\n",
    "    bn=True\n",
    "    miz=aud_model.Dynamic_Model(input_neurons=input_neurons,cross_validation=cross_validation,\n",
    "        nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy,\n",
    "        layers=layers,acts=acts,drops=drops,pools=pools,bn=bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode\n",
      "Activation 1 relu 2 relu 3 softmax\n",
      "Model CNN\n",
      "Epoch 1/10\n",
      " - 34s - loss: 1.8508 - acc: 0.3723\n",
      "Epoch 2/10\n",
      " - 34s - loss: 1.0339 - acc: 0.6477\n",
      "Epoch 3/10\n",
      " - 34s - loss: 0.8195 - acc: 0.7199\n",
      "Epoch 4/10\n",
      " - 34s - loss: 0.6883 - acc: 0.7657\n",
      "Epoch 5/10\n",
      " - 34s - loss: 0.5954 - acc: 0.7962\n",
      "Epoch 6/10\n",
      " - 34s - loss: 0.5327 - acc: 0.8193\n",
      "Epoch 7/10\n",
      " - 34s - loss: 0.4827 - acc: 0.8361\n",
      "Epoch 8/10\n",
      " - 30s - loss: 0.4478 - acc: 0.8477\n",
      "Epoch 9/10\n",
      " - 31s - loss: 0.4163 - acc: 0.8581\n",
      "Epoch 10/10\n",
      " - 34s - loss: 0.3951 - acc: 0.8657\n",
      "write out finished!\n",
      "Accuracy 61.03 prcnt\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1155)\n",
    "if cross_validation:\n",
    "    kf = KFold(len(tr_X),folds,shuffle=True,random_state=42)\n",
    "    results=[]    \n",
    "    for train_indices, test_indices in kf:\n",
    "        train_x = [tr_X[ii] for ii in train_indices]\n",
    "        train_y = [tr_y[ii] for ii in train_indices]\n",
    "        test_x  = [tr_X[ii] for ii in test_indices]\n",
    "        test_y  = [tr_y[ii] for ii in test_indices]\n",
    "        train_y = to_categorical(train_y,num_classes=len(labels))\n",
    "        test_y = to_categorical(test_y,num_classes=len(labels)) \n",
    "        \n",
    "        train_x=np.array(train_x)\n",
    "        train_y=np.array(train_y)\n",
    "        test_x=np.array(test_x)\n",
    "        test_y=np.array(test_y)\n",
    "        print \"Development Mode\"\n",
    "\n",
    "        #get compiled model\n",
    "        lrmodel=miz.prepare_model()\n",
    "\n",
    "        if lrmodel is None:\n",
    "            print \"If you have used Dynamic Model, make sure you pass correct parameters\"\n",
    "            raise SystemExit\n",
    "        #fit the model\n",
    "        lrmodel.fit(train_x,train_y,batch_size=miz.batchsize,epochs=miz.epochs,verbose=1)\n",
    "        \n",
    "        #make prediction\n",
    "        pred=lrmodel.predict(test_x, batch_size=32, verbose=2)\n",
    "\n",
    "        pred = [ii.argmax()for ii in pred]\n",
    "        test_y = [ii.argmax()for ii in test_y]\n",
    "\n",
    "        results.append(accuracy_score(pred,test_y))\n",
    "        print accuracy_score(pred,test_y)\n",
    "        jj=str(set(list(test_y)))\n",
    "        print \"Unique in test_y\",jj\n",
    "    print \"Results: \" + str( np.array(results).mean() )\n",
    "else:\n",
    "    train_x=np.array(tr_X)\n",
    "    train_y=np.array(tr_y)\n",
    "    print \"Evaluation mode\"\n",
    "    lrmodel=miz.prepare_model()\n",
    "    train_y = to_categorical(train_y,num_classes=len(labels))\n",
    "        \n",
    "    #fit the model\n",
    "    lrmodel.fit(train_x,train_y,batch_size=miz.batchsize,epochs=epochs,verbose=2)\n",
    "    if save_model:\n",
    "        lrmodel.save(modelx)\n",
    "        lrmodel = load_model(modelx)\n",
    "\n",
    "    truth,pred=test(lrmodel,txt_eva_path,new_p,model)\n",
    "\n",
    "    acc=aud_model.calculate_accuracy(truth,pred)\n",
    "    print \"Accuracy %.2f prcnt\"%acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
